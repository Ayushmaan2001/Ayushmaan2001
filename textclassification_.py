# -*- coding: utf-8 -*-
"""TextClassification .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nRkBxy3e1iYl6QSX9W_3UiVnf6tjw_lB
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np

data = keras.datasets.imdb

(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)

train_data[0]

d = data.get_word_index()

d

d = {k:(v+3) for k,v in d.items()}
d['<PAD>'] = 0
d['<START>'] = 1
d['<UNK>'] = 2
d['<UNUSED>'] = 3

d = {value : key for (key, value) in d.items()}

d

train_data = keras.preprocessing.sequence.pad_sequences(
    train_data, maxlen=250, value=0, padding='post',)

test_data = keras.preprocessing.sequence.pad_sequences(
    test_data, maxlen=250, value=0, padding='post',)

def decode(text):
  return " ".join([d.get(i,"?") for i in text])

len(test_data)
len(train_data)

model = keras.Sequential()

model.add(keras.layers.Embedding(10000, 16))
model.add(keras.layers.GlobalAveragePooling1D())
model.add(keras.layers.Dense(16, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

x_val = train_data[:10000]
x_train = train_data[10000:]

y_val = train_labels[:10000]
y_train = train_labels[10000:]

fitmodel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val,y_val), verbose=1)

result = model.evaluate(test_data, test_labels)
result